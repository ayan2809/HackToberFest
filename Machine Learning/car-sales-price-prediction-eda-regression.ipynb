{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Car Sales Price Prediction","metadata":{}},{"cell_type":"markdown","source":"# 1. Importing the libraries","metadata":{}},{"cell_type":"markdown","source":"A Python library is a collection of related modules. It contains bundles of code that can be used repeatedly in different programs. It makes Python Programming simpler and convenient for the programmer. As we don't need to write the same code again and again for different programs.\n\nIn this notebook, we will be using the following libraries.","metadata":{}},{"cell_type":"code","source":"### Data Wrangling \n\nimport numpy as np\nimport pandas as pd\nimport missingno\nfrom collections import Counter\nfrom collections import OrderedDict\n\n### Data Visualization\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n### Data Preprocessing\n\nimport statsmodels.api as sm\nfrom scipy import stats\n\n### Modelling \n\nfrom sklearn.model_selection import train_test_split\nfrom math import sqrt\nfrom sklearn.metrics import mean_squared_error, r2_score\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import Lasso\nfrom sklearn.linear_model import Ridge\nfrom sklearn.svm import SVR\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.ensemble import StackingRegressor\nimport xgboost as xg\n\n### Tabulating the results\n\nfrom tabulate import tabulate\n\n### Remove unnecessary warnings\n\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2022-08-10T02:10:30.983119Z","iopub.execute_input":"2022-08-10T02:10:30.983616Z","iopub.status.idle":"2022-08-10T02:10:32.690649Z","shell.execute_reply.started":"2022-08-10T02:10:30.983503Z","shell.execute_reply":"2022-08-10T02:10:32.689338Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. Importing the data","metadata":{}},{"cell_type":"markdown","source":"In this section, I will fetch the dataset that is available in the Kaggle's project description in the Data section.\n\nThe training set should be used to build your machine learning models. For the training set, we provide the outcome (also known as the “ground truth”) for each Car model. Your model will be based on “features” like Manufacturer, Model, Vehicle Type, Horsepower etc. You can also use feature engineering to create new features.\n\nThe test set should be used to see how well your model performs on unseen data. For the test set, we do not provide the ground truth. It is your job to predict these outcomes. For each car, our task is to predict the sales price of the car.","metadata":{}},{"cell_type":"code","source":"### Fetching the dataset\n\ndataset = pd.read_csv('../input/car-sales/Car_sales.csv')","metadata":{"execution":{"iopub.status.busy":"2022-08-10T02:10:32.692706Z","iopub.execute_input":"2022-08-10T02:10:32.693078Z","iopub.status.idle":"2022-08-10T02:10:32.722467Z","shell.execute_reply.started":"2022-08-10T02:10:32.693044Z","shell.execute_reply":"2022-08-10T02:10:32.721574Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Looking at the sample data in the dataset\n\ndataset.head(10)","metadata":{"execution":{"iopub.status.busy":"2022-08-10T02:10:32.724029Z","iopub.execute_input":"2022-08-10T02:10:32.725268Z","iopub.status.idle":"2022-08-10T02:10:32.764518Z","shell.execute_reply.started":"2022-08-10T02:10:32.725227Z","shell.execute_reply":"2022-08-10T02:10:32.763646Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Shape of the dataset\n\ndataset.shape","metadata":{"execution":{"iopub.status.busy":"2022-08-10T02:10:32.766975Z","iopub.execute_input":"2022-08-10T02:10:32.767794Z","iopub.status.idle":"2022-08-10T02:10:32.775133Z","shell.execute_reply.started":"2022-08-10T02:10:32.76775Z","shell.execute_reply":"2022-08-10T02:10:32.773764Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The dataset consists of 16 columns and 157 rows.","metadata":{}},{"cell_type":"markdown","source":"# 3. Exploratory Data Analysis","metadata":{}},{"cell_type":"markdown","source":"Exploratory Data Analysis refers to the critical process of performing initial investigations on data so as to discover patterns,to spot anomalies,to test hypothesis and to check assumptions with the help of summary statistics and graphical representations.\n\nHere, we will perform EDA on the categorical columns of the dataset - Manufacturer, Vehicle_type and the numerical columns of the dataset - Sales_in_thousands, __year_resale_value, Price_in_thousands, Engine_size, Horsepower, Wheelbase, Width, Length, Curb_weight, Fuel_capacity, Fuel_efficiency, Power_perf_factor.","metadata":{}},{"cell_type":"markdown","source":"# 3.1 Datatypes, Missing Data, and Summary Statistics","metadata":{}},{"cell_type":"code","source":"### Looking at the datatypes of the dataset\n\ndataset.info()","metadata":{"execution":{"iopub.status.busy":"2022-08-10T02:10:32.776836Z","iopub.execute_input":"2022-08-10T02:10:32.777431Z","iopub.status.idle":"2022-08-10T02:10:32.809738Z","shell.execute_reply.started":"2022-08-10T02:10:32.777395Z","shell.execute_reply":"2022-08-10T02:10:32.808198Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Here, the columns - Manufacturer, Model, Vehicle_type are categorical. Hence, we modify the datatype of these columns to category.","metadata":{}},{"cell_type":"code","source":"### Modifying the datatypes of the columns to category\n\ndataset.Manufacturer = dataset.Manufacturer.astype('category')\ndataset.Model = dataset.Model.astype('category')\ndataset.Vehicle_type = dataset.Vehicle_type.astype('category')","metadata":{"execution":{"iopub.status.busy":"2022-08-10T02:10:32.811242Z","iopub.execute_input":"2022-08-10T02:10:32.811633Z","iopub.status.idle":"2022-08-10T02:10:32.82548Z","shell.execute_reply.started":"2022-08-10T02:10:32.811585Z","shell.execute_reply":"2022-08-10T02:10:32.824366Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Looking at the modified datatypes of the columns in the dataset.","metadata":{}},{"cell_type":"code","source":"### Looking at the modified datatypes of the dataset\n\ndataset.info()","metadata":{"execution":{"iopub.status.busy":"2022-08-10T02:10:32.827184Z","iopub.execute_input":"2022-08-10T02:10:32.827945Z","iopub.status.idle":"2022-08-10T02:10:32.846266Z","shell.execute_reply.started":"2022-08-10T02:10:32.827862Z","shell.execute_reply":"2022-08-10T02:10:32.845336Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From the above data it is evident that there are missing values in the dataset.","metadata":{}},{"cell_type":"code","source":"### Visual representation of the missing data in the dataset\n\nmissingno.matrix(dataset)","metadata":{"execution":{"iopub.status.busy":"2022-08-10T02:10:32.847657Z","iopub.execute_input":"2022-08-10T02:10:32.848079Z","iopub.status.idle":"2022-08-10T02:10:33.462365Z","shell.execute_reply.started":"2022-08-10T02:10:32.847982Z","shell.execute_reply":"2022-08-10T02:10:33.461477Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From the above dataset, we can see that there are missing values in the column - __year_resale_value, Price_in_thousands, Engine_size, Horsepower, Wheelbase, Width, Length, Curb_weight, Fuel_capacity, Fuel_efficiency, Power_perf_factor.","metadata":{}},{"cell_type":"code","source":"### Summary statistics of the numerical columns in the dataset\n\ndataset.describe()","metadata":{"execution":{"iopub.status.busy":"2022-08-10T02:10:33.463498Z","iopub.execute_input":"2022-08-10T02:10:33.464301Z","iopub.status.idle":"2022-08-10T02:10:33.514101Z","shell.execute_reply.started":"2022-08-10T02:10:33.464266Z","shell.execute_reply":"2022-08-10T02:10:33.513306Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3.2 Feature Analysis","metadata":{}},{"cell_type":"markdown","source":"# 3.2.1 Categorical variable - Manufacturer","metadata":{}},{"cell_type":"code","source":"### Value counts of the column - Manufacturer\n\nmanufacturer_count = dataset['Manufacturer'].value_counts(dropna = False)\nmanufacturer_count","metadata":{"execution":{"iopub.status.busy":"2022-08-10T02:10:33.517589Z","iopub.execute_input":"2022-08-10T02:10:33.518099Z","iopub.status.idle":"2022-08-10T02:10:33.527246Z","shell.execute_reply.started":"2022-08-10T02:10:33.518066Z","shell.execute_reply":"2022-08-10T02:10:33.526172Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Bar graph showing the value counts of the column - Manufacturer\n\nplt.figure(figsize = (20, 6))\nsns.barplot(manufacturer_count.index, manufacturer_count.values, alpha = 0.8)\nplt.title('Bar graph showing the value counts of the column - Manufacturer')\nplt.ylabel('Number of Occurrences', fontsize = 12)\nplt.xlabel('Manufacturer', fontsize = 12)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-08-10T02:10:33.528845Z","iopub.execute_input":"2022-08-10T02:10:33.529455Z","iopub.status.idle":"2022-08-10T02:10:33.954611Z","shell.execute_reply.started":"2022-08-10T02:10:33.529421Z","shell.execute_reply":"2022-08-10T02:10:33.953454Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From the above graph, we can see that the number of occurences of the car manufacturers is not uniformly distributed.","metadata":{}},{"cell_type":"code","source":"### Mean price per each Manufacturer \n\nmean_price_manufacturer = dataset[['Manufacturer', 'Price_in_thousands']].groupby('Manufacturer', as_index = False).mean()\nmean_price_manufacturer","metadata":{"execution":{"iopub.status.busy":"2022-08-10T02:10:33.956367Z","iopub.execute_input":"2022-08-10T02:10:33.956934Z","iopub.status.idle":"2022-08-10T02:10:33.978346Z","shell.execute_reply.started":"2022-08-10T02:10:33.956888Z","shell.execute_reply":"2022-08-10T02:10:33.977007Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Mean Price for each Manufacturer\n\nplt.figure(figsize = (20, 6))\nsns.barplot(mean_price_manufacturer['Manufacturer'], mean_price_manufacturer['Price_in_thousands'], alpha = 0.8)\nplt.title('Mean Sales Price for each Manufacturer')\nplt.ylabel('Mean Price', fontsize = 12)\nplt.xlabel('Manufacturer', fontsize = 12)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-08-10T02:10:33.980248Z","iopub.execute_input":"2022-08-10T02:10:33.980741Z","iopub.status.idle":"2022-08-10T02:10:34.429047Z","shell.execute_reply.started":"2022-08-10T02:10:33.980696Z","shell.execute_reply":"2022-08-10T02:10:34.427727Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3.2.2 Categorical variable - Vehicle_type","metadata":{}},{"cell_type":"code","source":"### Value counts of the column - Vehicle_type\n\nvehicle_count = dataset['Vehicle_type'].value_counts(dropna = False)\nvehicle_count","metadata":{"execution":{"iopub.status.busy":"2022-08-10T02:10:34.430309Z","iopub.execute_input":"2022-08-10T02:10:34.430673Z","iopub.status.idle":"2022-08-10T02:10:34.440443Z","shell.execute_reply.started":"2022-08-10T02:10:34.430639Z","shell.execute_reply":"2022-08-10T02:10:34.439246Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Bar graph showing the value counts of the column - Vehicle_type\n\nsns.barplot(vehicle_count.index, vehicle_count.values, alpha = 0.8)\nplt.title('Bar graph showing the value counts of the column - Vehicle type')\nplt.ylabel('Number of Occurrences', fontsize = 12)\nplt.xlabel('Vehicle type', fontsize = 12)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-08-10T02:10:34.442193Z","iopub.execute_input":"2022-08-10T02:10:34.442551Z","iopub.status.idle":"2022-08-10T02:10:34.77075Z","shell.execute_reply.started":"2022-08-10T02:10:34.442512Z","shell.execute_reply":"2022-08-10T02:10:34.769377Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From the above graph, we can see that most of the values in the column are Passenger.","metadata":{}},{"cell_type":"code","source":"### Mean price per each Vehicle type\n\nmean_price_vehicle = dataset[['Vehicle_type', 'Price_in_thousands']].groupby('Vehicle_type', as_index = False).mean()\nmean_price_vehicle","metadata":{"execution":{"iopub.status.busy":"2022-08-10T02:10:34.774771Z","iopub.execute_input":"2022-08-10T02:10:34.77515Z","iopub.status.idle":"2022-08-10T02:10:34.790353Z","shell.execute_reply.started":"2022-08-10T02:10:34.775114Z","shell.execute_reply":"2022-08-10T02:10:34.788976Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Mean Price for each Vehicle_type\n\nsns.barplot(mean_price_vehicle['Vehicle_type'], mean_price_vehicle['Price_in_thousands'], alpha = 0.8)\nplt.title('Mean Sales Price for each Vehicle type')\nplt.ylabel('Mean Price', fontsize = 12)\nplt.xlabel('Vehicle type', fontsize = 12)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-08-10T02:10:34.792113Z","iopub.execute_input":"2022-08-10T02:10:34.793382Z","iopub.status.idle":"2022-08-10T02:10:34.975082Z","shell.execute_reply.started":"2022-08-10T02:10:34.793333Z","shell.execute_reply":"2022-08-10T02:10:34.973922Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From the above graph, we can see that the mean sales price is similar for both the vehicle types.","metadata":{}},{"cell_type":"markdown","source":"# 3.2.3 Numerical variable - Sales_in_thousands","metadata":{}},{"cell_type":"code","source":"### Understanding the distribution of the column - Sales_in_thousands\n\nsns.distplot(dataset['Sales_in_thousands'], label = 'Skewness: %.2f'%(dataset['Sales_in_thousands'].skew()))\nplt.legend(loc = 'best')\nplt.title('Distribution of the column - Sales in thousands')","metadata":{"execution":{"iopub.status.busy":"2022-08-10T02:10:34.976958Z","iopub.execute_input":"2022-08-10T02:10:34.977334Z","iopub.status.idle":"2022-08-10T02:10:35.287511Z","shell.execute_reply.started":"2022-08-10T02:10:34.9773Z","shell.execute_reply":"2022-08-10T02:10:35.286322Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From the above graph, we can see that the data is slightly skewed. We will remove this skewness during the Data Preprocessing phase.","metadata":{}},{"cell_type":"markdown","source":"# 3.2.4 Numerical variable - __year_resale_value","metadata":{}},{"cell_type":"code","source":"### Understanding the distribution of the column - __year_resale_value\n\nsns.distplot(dataset['__year_resale_value'], label = 'Skewness: %.2f'%(dataset['__year_resale_value'].skew()))\nplt.legend(loc = 'best')\nplt.title('Distribution of the column - __year_resale_value')","metadata":{"execution":{"iopub.status.busy":"2022-08-10T02:10:35.28906Z","iopub.execute_input":"2022-08-10T02:10:35.289429Z","iopub.status.idle":"2022-08-10T02:10:35.564784Z","shell.execute_reply.started":"2022-08-10T02:10:35.289395Z","shell.execute_reply":"2022-08-10T02:10:35.563552Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From the above graph, we can see that the data is slightly skewed. We will remove this skewness during the Data Preprocessing phase.","metadata":{}},{"cell_type":"markdown","source":"# 3.2.5 Numerical variable - Price_in_thousands","metadata":{}},{"cell_type":"code","source":"### Understanding the distribution of the column - Price_in_thousands\n\nsns.distplot(dataset['Price_in_thousands'], label = 'Skewness: %.2f'%(dataset['Price_in_thousands'].skew()))\nplt.legend(loc = 'best')\nplt.title('Distribution of the column - Price_in_thousands')","metadata":{"execution":{"iopub.status.busy":"2022-08-10T02:10:35.566245Z","iopub.execute_input":"2022-08-10T02:10:35.566713Z","iopub.status.idle":"2022-08-10T02:10:35.822233Z","shell.execute_reply.started":"2022-08-10T02:10:35.566679Z","shell.execute_reply":"2022-08-10T02:10:35.820951Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From the above graph, we can see that the data is slightly skewed. We will remove this skewness during the Data Preprocessing phase.","metadata":{}},{"cell_type":"markdown","source":"# 3.2.6 Numerical variable - Engine_size","metadata":{}},{"cell_type":"code","source":"### Understanding the distribution of the column - Engine_size\n\nsns.distplot(dataset['Engine_size'], label = 'Skewness: %.2f'%(dataset['Engine_size'].skew()))\nplt.legend(loc = 'best')\nplt.title('Distribution of the column - Engine_size')","metadata":{"execution":{"iopub.status.busy":"2022-08-10T02:10:35.823786Z","iopub.execute_input":"2022-08-10T02:10:35.824161Z","iopub.status.idle":"2022-08-10T02:10:36.093363Z","shell.execute_reply.started":"2022-08-10T02:10:35.82409Z","shell.execute_reply":"2022-08-10T02:10:36.092431Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From the above graph, we can see that the data is slightly skewed. We will remove this skewness during the Data Preprocessing phase.","metadata":{}},{"cell_type":"markdown","source":"# 3.2.7 Numerical variable - Horsepower","metadata":{}},{"cell_type":"code","source":"### Understanding the distribution of the column - Horsepower\n\nsns.distplot(dataset['Horsepower'], label = 'Skewness: %.2f'%(dataset['Horsepower'].skew()))\nplt.legend(loc = 'best')\nplt.title('Distribution of the column - Horsepower')","metadata":{"execution":{"iopub.status.busy":"2022-08-10T02:10:36.094476Z","iopub.execute_input":"2022-08-10T02:10:36.095673Z","iopub.status.idle":"2022-08-10T02:10:36.312054Z","shell.execute_reply.started":"2022-08-10T02:10:36.095622Z","shell.execute_reply":"2022-08-10T02:10:36.310753Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From the above graph, we can see that the data is slightly skewed. We will remove this skewness during the Data Preprocessing phase.","metadata":{}},{"cell_type":"markdown","source":"# 3.2.8 Numerical variable - Wheelbase","metadata":{}},{"cell_type":"code","source":"### Understanding the distribution of the column - Wheelbase\n\nsns.distplot(dataset['Wheelbase'], label = 'Skewness: %.2f'%(dataset['Wheelbase'].skew()))\nplt.legend(loc = 'best')\nplt.title('Distribution of the column - Wheelbase')","metadata":{"execution":{"iopub.status.busy":"2022-08-10T02:10:36.313614Z","iopub.execute_input":"2022-08-10T02:10:36.314529Z","iopub.status.idle":"2022-08-10T02:10:36.522409Z","shell.execute_reply.started":"2022-08-10T02:10:36.31449Z","shell.execute_reply":"2022-08-10T02:10:36.521231Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From the above graph, we can see that the data is slightly skewed. We will remove this skewness during the Data Preprocessing phase.","metadata":{}},{"cell_type":"markdown","source":"# 3.2.9 Numerical variable - Width","metadata":{}},{"cell_type":"code","source":"### Understanding the distribution of the column - Width\n\nsns.distplot(dataset['Width'], label = 'Skewness: %.2f'%(dataset['Width'].skew()))\nplt.legend(loc = 'best')\nplt.title('Distribution of the column - Width')","metadata":{"execution":{"iopub.status.busy":"2022-08-10T02:10:36.523943Z","iopub.execute_input":"2022-08-10T02:10:36.525015Z","iopub.status.idle":"2022-08-10T02:10:36.767062Z","shell.execute_reply.started":"2022-08-10T02:10:36.524967Z","shell.execute_reply":"2022-08-10T02:10:36.766131Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From the above graph, we can see that the data is normally distributed.","metadata":{}},{"cell_type":"markdown","source":"# 3.2.10 Numerical variable - Length","metadata":{}},{"cell_type":"code","source":"### Understanding the distribution of the column - Length\n\nsns.distplot(dataset['Length'], label = 'Skewness: %.2f'%(dataset['Length'].skew()))\nplt.legend(loc = 'best')\nplt.title('Distribution of the column - Length')","metadata":{"execution":{"iopub.status.busy":"2022-08-10T02:10:36.768379Z","iopub.execute_input":"2022-08-10T02:10:36.769621Z","iopub.status.idle":"2022-08-10T02:10:37.032271Z","shell.execute_reply.started":"2022-08-10T02:10:36.769545Z","shell.execute_reply":"2022-08-10T02:10:37.031098Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From the above graph, we can see that the data is normally distributed.","metadata":{}},{"cell_type":"markdown","source":"# 3.2.11 Numerical variable - Curb_weight","metadata":{}},{"cell_type":"code","source":"### Understanding the distribution of the column - Curb_weight\n\nsns.distplot(dataset['Curb_weight'], label = 'Skewness: %.2f'%(dataset['Curb_weight'].skew()))\nplt.legend(loc = 'best')\nplt.title('Distribution of the column - Curb_weight')","metadata":{"execution":{"iopub.status.busy":"2022-08-10T02:10:37.033639Z","iopub.execute_input":"2022-08-10T02:10:37.03401Z","iopub.status.idle":"2022-08-10T02:10:37.297126Z","shell.execute_reply.started":"2022-08-10T02:10:37.033972Z","shell.execute_reply":"2022-08-10T02:10:37.295674Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From the above graph, we can see that the data is normally distributed.","metadata":{}},{"cell_type":"markdown","source":"# 3.2.12 Numerical variable - Fuel_capacity","metadata":{}},{"cell_type":"code","source":"### Understanding the distribution of the column - Fuel_capacity\n\nsns.distplot(dataset['Fuel_capacity'], label = 'Skewness: %.2f'%(dataset['Fuel_capacity'].skew()))\nplt.legend(loc = 'best')\nplt.title('Distribution of the column - Fuel_capacity')","metadata":{"execution":{"iopub.status.busy":"2022-08-10T02:10:37.298514Z","iopub.execute_input":"2022-08-10T02:10:37.298861Z","iopub.status.idle":"2022-08-10T02:10:37.575851Z","shell.execute_reply.started":"2022-08-10T02:10:37.298831Z","shell.execute_reply":"2022-08-10T02:10:37.574913Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From the above graph, we can see that the data is slightly skewed. We will remove this skewness during the Data Preprocessing phase.","metadata":{}},{"cell_type":"markdown","source":"# 3.2.13 Numerical variable - Fuel_efficiency","metadata":{}},{"cell_type":"code","source":"### Understanding the distribution of the column - Fuel_efficiency\n\nsns.distplot(dataset['Fuel_efficiency'], label = 'Skewness: %.2f'%(dataset['Fuel_efficiency'].skew()))\nplt.legend(loc = 'best')\nplt.title('Distribution of the column - Fuel_efficiency')","metadata":{"execution":{"iopub.status.busy":"2022-08-10T02:10:37.583794Z","iopub.execute_input":"2022-08-10T02:10:37.585266Z","iopub.status.idle":"2022-08-10T02:10:37.868709Z","shell.execute_reply.started":"2022-08-10T02:10:37.585226Z","shell.execute_reply":"2022-08-10T02:10:37.867465Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From the above graph, we can see that the data is normally distributed.","metadata":{}},{"cell_type":"markdown","source":"# 3.2.14 Numerical variable - Power_perf_factor","metadata":{}},{"cell_type":"code","source":"### Understanding the distribution of the column - Power_perf_factor\n\nsns.distplot(dataset['Power_perf_factor'], label = 'Skewness: %.2f'%(dataset['Power_perf_factor'].skew()))\nplt.legend(loc = 'best')\nplt.title('Distribution of the column - Power_perf_factor')","metadata":{"execution":{"iopub.status.busy":"2022-08-10T02:10:37.870271Z","iopub.execute_input":"2022-08-10T02:10:37.870869Z","iopub.status.idle":"2022-08-10T02:10:38.139627Z","shell.execute_reply.started":"2022-08-10T02:10:37.870833Z","shell.execute_reply":"2022-08-10T02:10:38.138657Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From the above graph, we can see that the data is slightly skewed. We will remove this skewness during the Data Preprocessing phase.","metadata":{}},{"cell_type":"markdown","source":"# 4. Data Preprocessing","metadata":{}},{"cell_type":"markdown","source":"Data preprocessing is the process of getting our dataset ready for model training. In this section, we will perform the following preprocessing steps:\n\n1. Detect and remove outliers in numerical variables\n2. Drop and fill missing values\n3. Feature Engineering\n4. Data Trasformation\n5. Feature Encoding\n6. Feature Selection","metadata":{}},{"cell_type":"markdown","source":"# 4.1 Detect and remove outliers in numerical variables","metadata":{}},{"cell_type":"markdown","source":"Outliers are data points that have extreme values and they do not conform with the majority of the data. It is important to address this because outliers tend to skew our data towards extremes and can cause inaccurate model predictions. I will use the Tukey method to remove these outliers.\n\nHere, we will write a function that will loop through a list of features and detect outliers in each one of those features. In each loop, a data point is deemed an outlier if it is less than the first quartile minus the outlier step or exceeds third quartile plus the outlier step. The outlier step is defined as 1.5 times the interquartile range. Once the outliers have been determined for one feature, their indices will be stored in a list before proceeding to the next feature and the process repeats until the very last feature is completed. Finally, using the list with outlier indices, we will count the frequencies of the index numbers and return them if their frequency exceeds n times.","metadata":{}},{"cell_type":"code","source":"def detect_outliers(df, n, features_list):\n    outlier_indices = [] \n    for feature in features_list: \n        Q1 = np.percentile(df[feature], 25)\n        Q3 = np.percentile(df[feature], 75)\n        IQR = Q3 - Q1\n        outlier_step = 1.5 * IQR \n        outlier_list_col = df[(df[feature] < Q1 - outlier_step) | (df[feature] > Q3 + outlier_step)].index\n        outlier_indices.extend(outlier_list_col) \n    outlier_indices = Counter(outlier_indices)\n    multiple_outliers = list(key for key, value in outlier_indices.items() if value > n) \n    return multiple_outliers\n\noutliers_to_drop = detect_outliers(dataset, 2, ['Sales_in_thousands', '__year_resale_value', 'Price_in_thousands', \n                                               'Engine_size', 'Horsepower', 'Wheelbase', 'Width', 'Length', 'Curb_weight',\n                                               'Fuel_capacity', 'Fuel_efficiency', 'Power_perf_factor'])\nprint(\"We will drop these {} indices: \".format(len(outliers_to_drop)), outliers_to_drop)","metadata":{"execution":{"iopub.status.busy":"2022-08-10T02:10:38.1408Z","iopub.execute_input":"2022-08-10T02:10:38.141361Z","iopub.status.idle":"2022-08-10T02:10:38.167484Z","shell.execute_reply.started":"2022-08-10T02:10:38.141325Z","shell.execute_reply":"2022-08-10T02:10:38.166249Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From the above cell, we can see that there are no outliers in the data.","metadata":{}},{"cell_type":"markdown","source":"# 4.2 Drop and fill missing values","metadata":{}},{"cell_type":"markdown","source":"We will first remove the records that have missing Price_in_thousands.","metadata":{}},{"cell_type":"code","source":"### Filtering the rows that has a value in the column - Price_in_thousands\n\nmodified_dataset = dataset[dataset['Price_in_thousands'].notna()]\nmodified_dataset","metadata":{"execution":{"iopub.status.busy":"2022-08-10T02:10:38.169048Z","iopub.execute_input":"2022-08-10T02:10:38.169398Z","iopub.status.idle":"2022-08-10T02:10:38.210471Z","shell.execute_reply.started":"2022-08-10T02:10:38.169366Z","shell.execute_reply":"2022-08-10T02:10:38.209243Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Looking at the missing values in the dataset\n\nmodified_dataset.isnull().sum().sort_values(ascending = False)","metadata":{"execution":{"iopub.status.busy":"2022-08-10T02:10:38.211824Z","iopub.execute_input":"2022-08-10T02:10:38.212772Z","iopub.status.idle":"2022-08-10T02:10:38.224324Z","shell.execute_reply.started":"2022-08-10T02:10:38.212722Z","shell.execute_reply":"2022-08-10T02:10:38.223128Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From the modified dataset, we can see that there are missing values in the columns - __year_resale_value, Fuel_efficiency, Curb_weight.","metadata":{}},{"cell_type":"markdown","source":"# 4.2.1 Handling missing values - __year_resale_value","metadata":{}},{"cell_type":"code","source":"### Replacing the missing values in the column - __year_resale_value using median\n\nyear_index = list(~modified_dataset['__year_resale_value'].isnull())\nmedian_year = np.median(modified_dataset['__year_resale_value'].loc[year_index])\nmedian_year","metadata":{"execution":{"iopub.status.busy":"2022-08-10T02:10:38.226054Z","iopub.execute_input":"2022-08-10T02:10:38.226541Z","iopub.status.idle":"2022-08-10T02:10:38.239646Z","shell.execute_reply.started":"2022-08-10T02:10:38.226492Z","shell.execute_reply":"2022-08-10T02:10:38.23825Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Replacing the missing values of the column - __year_resale_value in the dataset\n\nmodified_dataset['__year_resale_value'].fillna(median_year, inplace = True)","metadata":{"execution":{"iopub.status.busy":"2022-08-10T02:10:38.240976Z","iopub.execute_input":"2022-08-10T02:10:38.241341Z","iopub.status.idle":"2022-08-10T02:10:38.249859Z","shell.execute_reply.started":"2022-08-10T02:10:38.241308Z","shell.execute_reply":"2022-08-10T02:10:38.248774Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Checking if there are any missing values of __year_resale_value in the dataset\n\nmodified_dataset['__year_resale_value'].isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2022-08-10T02:10:38.25152Z","iopub.execute_input":"2022-08-10T02:10:38.251953Z","iopub.status.idle":"2022-08-10T02:10:38.265911Z","shell.execute_reply.started":"2022-08-10T02:10:38.251918Z","shell.execute_reply":"2022-08-10T02:10:38.264652Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4.2.2 Handling missing values - Fuel_efficiency","metadata":{}},{"cell_type":"code","source":"### Replacing the missing values in the column - Fuel_efficiency using median\n\nfuel_index = list(~modified_dataset['Fuel_efficiency'].isnull())\nmedian_fuel = np.median(modified_dataset['Fuel_efficiency'].loc[fuel_index])\nmedian_fuel","metadata":{"execution":{"iopub.status.busy":"2022-08-10T02:10:38.267854Z","iopub.execute_input":"2022-08-10T02:10:38.26836Z","iopub.status.idle":"2022-08-10T02:10:38.279767Z","shell.execute_reply.started":"2022-08-10T02:10:38.268316Z","shell.execute_reply":"2022-08-10T02:10:38.278516Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Replacing the missing values of the column - Fuel_efficiency in the dataset\n\nmodified_dataset['Fuel_efficiency'].fillna(median_year, inplace = True)","metadata":{"execution":{"iopub.status.busy":"2022-08-10T02:10:38.281262Z","iopub.execute_input":"2022-08-10T02:10:38.281885Z","iopub.status.idle":"2022-08-10T02:10:38.290359Z","shell.execute_reply.started":"2022-08-10T02:10:38.281852Z","shell.execute_reply":"2022-08-10T02:10:38.289053Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Checking if there are any missing values of Fuel_efficiency in the dataset\n\nmodified_dataset['Fuel_efficiency'].isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2022-08-10T02:10:38.291903Z","iopub.execute_input":"2022-08-10T02:10:38.293081Z","iopub.status.idle":"2022-08-10T02:10:38.306074Z","shell.execute_reply.started":"2022-08-10T02:10:38.29303Z","shell.execute_reply":"2022-08-10T02:10:38.304971Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4.2.3 Handling missing values - Curb_weight","metadata":{}},{"cell_type":"code","source":"### Replacing the missing values in the column - Curb_weight using median\n\ncurb_index = list(~modified_dataset['Curb_weight'].isnull())\nmedian_curb = np.median(modified_dataset['Curb_weight'].loc[curb_index])\nmedian_curb","metadata":{"execution":{"iopub.status.busy":"2022-08-10T02:10:38.307442Z","iopub.execute_input":"2022-08-10T02:10:38.307916Z","iopub.status.idle":"2022-08-10T02:10:38.322933Z","shell.execute_reply.started":"2022-08-10T02:10:38.307873Z","shell.execute_reply":"2022-08-10T02:10:38.321931Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Replacing the missing values of the column - Curb_weight in the dataset\n\nmodified_dataset['Curb_weight'].fillna(median_curb, inplace = True)","metadata":{"execution":{"iopub.status.busy":"2022-08-10T02:10:38.324213Z","iopub.execute_input":"2022-08-10T02:10:38.324546Z","iopub.status.idle":"2022-08-10T02:10:38.332187Z","shell.execute_reply.started":"2022-08-10T02:10:38.324517Z","shell.execute_reply":"2022-08-10T02:10:38.331127Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Checking if there are any missing values of Curb_weight in the dataset\n\nmodified_dataset['Curb_weight'].isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2022-08-10T02:10:38.334Z","iopub.execute_input":"2022-08-10T02:10:38.334547Z","iopub.status.idle":"2022-08-10T02:10:38.349147Z","shell.execute_reply.started":"2022-08-10T02:10:38.334501Z","shell.execute_reply":"2022-08-10T02:10:38.348036Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4.2.4 Dropping unnecessary columns","metadata":{}},{"cell_type":"markdown","source":"Here, we will drop the columns - Model from the dataset.","metadata":{}},{"cell_type":"code","source":"### Dropping the columns - Model\n\nmodified_dataset.drop(['Model'], axis = 1, inplace = True)\nmodified_dataset","metadata":{"execution":{"iopub.status.busy":"2022-08-10T02:10:38.350683Z","iopub.execute_input":"2022-08-10T02:10:38.351456Z","iopub.status.idle":"2022-08-10T02:10:38.391424Z","shell.execute_reply.started":"2022-08-10T02:10:38.351402Z","shell.execute_reply":"2022-08-10T02:10:38.390169Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4.3 Feature Engineering","metadata":{}},{"cell_type":"markdown","source":"Feature engineering is arguably the most important art in machine learning. It is the process of creating new features from existing features to better represent the underlying problem to the predictive models resulting in improved model accuracy on unseen data.\n\nHere, we focus on creating new columns for:\n\n1. NewManufacturer - using the column Manufacturer\n2. Age - using the column Latest_Launch","metadata":{}},{"cell_type":"markdown","source":"# 4.3.1 NewManufacturer - using the column Manufacturer","metadata":{}},{"cell_type":"markdown","source":"Here, we will create the NewManufacturer column such that if the mean price of a Manufacturer is less than 30 then it belongs to class 1, else class 2.","metadata":{}},{"cell_type":"code","source":"### Seperating the Manufacturers into class 1 and 2\n\nclass_1 = []\nclass_2 = []\n\nfor index in range(len(mean_price_manufacturer)):\n    if mean_price_manufacturer.iloc[index, 1] <= 30:\n        class_1.append(mean_price_manufacturer.iloc[index, 0])\n    else:\n        class_2.append(mean_price_manufacturer.iloc[index, 0])\n        \nprint('Manufacturers with less than 30 mean price: ', class_1)\nprint('Manufacturers with more than 30 mean price: ', class_2)","metadata":{"execution":{"iopub.status.busy":"2022-08-10T02:10:38.392812Z","iopub.execute_input":"2022-08-10T02:10:38.393408Z","iopub.status.idle":"2022-08-10T02:10:38.407648Z","shell.execute_reply.started":"2022-08-10T02:10:38.393372Z","shell.execute_reply":"2022-08-10T02:10:38.406075Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Modifying the Manufacturer column in the dataset\n\nmanufacturer_data = modified_dataset['Manufacturer']\nnew_manufacturer_data = []\n\nfor value in manufacturer_data:\n    if value in class_1:\n        new_manufacturer_data.append(1)\n    else:\n        new_manufacturer_data.append(2)\n        \nmodified_dataset['Manufacturer'] = new_manufacturer_data","metadata":{"execution":{"iopub.status.busy":"2022-08-10T02:10:38.408832Z","iopub.execute_input":"2022-08-10T02:10:38.41016Z","iopub.status.idle":"2022-08-10T02:10:38.426854Z","shell.execute_reply.started":"2022-08-10T02:10:38.410121Z","shell.execute_reply":"2022-08-10T02:10:38.425648Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Looking at the modified dataset\n\nmodified_dataset","metadata":{"execution":{"iopub.status.busy":"2022-08-10T02:10:38.428446Z","iopub.execute_input":"2022-08-10T02:10:38.428983Z","iopub.status.idle":"2022-08-10T02:10:38.469242Z","shell.execute_reply.started":"2022-08-10T02:10:38.428946Z","shell.execute_reply":"2022-08-10T02:10:38.467968Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4.3.2 Age - using the column Latest_Launch","metadata":{}},{"cell_type":"markdown","source":"Here, we will create the Age column using the formula 2022 - year value.","metadata":{}},{"cell_type":"code","source":"### Creating the Age data\n\nage_data = []\nlaunch_data = modified_dataset['Latest_Launch']\n\nfor value in launch_data:\n    year = int(value.split('/')[-1])\n    age_data.append(2022 - year)","metadata":{"execution":{"iopub.status.busy":"2022-08-10T02:10:38.472352Z","iopub.execute_input":"2022-08-10T02:10:38.473374Z","iopub.status.idle":"2022-08-10T02:10:38.480944Z","shell.execute_reply.started":"2022-08-10T02:10:38.473323Z","shell.execute_reply":"2022-08-10T02:10:38.479636Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Adding the Age column\n\nmodified_dataset['Age'] = age_data\nmodified_dataset","metadata":{"execution":{"iopub.status.busy":"2022-08-10T02:10:38.482397Z","iopub.execute_input":"2022-08-10T02:10:38.482767Z","iopub.status.idle":"2022-08-10T02:10:38.523483Z","shell.execute_reply.started":"2022-08-10T02:10:38.482733Z","shell.execute_reply":"2022-08-10T02:10:38.522076Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Understanding the distribution of the column - Age\n\nsns.distplot(modified_dataset['Age'], label = 'Skewness: %.2f'%(modified_dataset['Age'].skew()))\nplt.legend(loc = 'best')\nplt.title('Distribution of the column - Age')","metadata":{"execution":{"iopub.status.busy":"2022-08-10T02:10:38.52598Z","iopub.execute_input":"2022-08-10T02:10:38.52641Z","iopub.status.idle":"2022-08-10T02:10:38.781225Z","shell.execute_reply.started":"2022-08-10T02:10:38.526375Z","shell.execute_reply":"2022-08-10T02:10:38.779939Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From the above graph, we can see that there are only 3 main values for this column.","metadata":{}},{"cell_type":"code","source":"### Dropping the column - Latest_Launch\n\nmodified_dataset.drop(['Latest_Launch'], axis = 1, inplace = True)","metadata":{"execution":{"iopub.status.busy":"2022-08-10T02:10:38.782692Z","iopub.execute_input":"2022-08-10T02:10:38.783056Z","iopub.status.idle":"2022-08-10T02:10:38.790484Z","shell.execute_reply.started":"2022-08-10T02:10:38.783017Z","shell.execute_reply":"2022-08-10T02:10:38.789406Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Looking at the modified dataset\n\nmodified_dataset","metadata":{"execution":{"iopub.status.busy":"2022-08-10T02:10:38.792104Z","iopub.execute_input":"2022-08-10T02:10:38.792705Z","iopub.status.idle":"2022-08-10T02:10:38.82592Z","shell.execute_reply.started":"2022-08-10T02:10:38.79266Z","shell.execute_reply":"2022-08-10T02:10:38.824705Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4.4 Data Transformation","metadata":{}},{"cell_type":"markdown","source":"In this section, we will remove the skewness present in the columns - Sales_in_thousands, __year_resale_value, Engine_size, Horsepower, Fuel_capacity, Power_perf_factor by using a Box-Cox transformation on the data. Then, we will normalize all the numerical columns apart from the Target using MinMax Normalization.","metadata":{}},{"cell_type":"markdown","source":"# 4.4.1 Box Cox transforming the column - Sales_in_thousands","metadata":{}},{"cell_type":"code","source":"### Understanding the distribution of the column - Sales_in_thousands\n\nsns.distplot(modified_dataset['Sales_in_thousands'], label = 'Skewness: %.2f'%(modified_dataset['Sales_in_thousands'].skew()))\nplt.legend(loc = 'best')\nplt.title('Distribution of the column - Sales_in_thousands')","metadata":{"execution":{"iopub.status.busy":"2022-08-10T02:10:38.827781Z","iopub.execute_input":"2022-08-10T02:10:38.8284Z","iopub.status.idle":"2022-08-10T02:10:39.160469Z","shell.execute_reply.started":"2022-08-10T02:10:38.828359Z","shell.execute_reply":"2022-08-10T02:10:39.159182Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Understanding the distribution of the data Box_Cox(Sales_in_thousands)\n\nsales_data = [1 if value == 0 else value for value in modified_dataset['Sales_in_thousands']]\n\nmodified_sales, _ = stats.boxcox(sales_data)\nmodified_dataset['Sales_in_thousands'] = modified_sales\n\nsns.distplot(modified_dataset['Sales_in_thousands'], label = 'Skewness: %.2f'%(modified_dataset['Sales_in_thousands'].skew()))\nplt.legend(loc = 'best')\nplt.title('Distribution of the column - Sales_in_thousands')","metadata":{"execution":{"iopub.status.busy":"2022-08-10T02:10:39.161726Z","iopub.execute_input":"2022-08-10T02:10:39.162165Z","iopub.status.idle":"2022-08-10T02:10:39.44345Z","shell.execute_reply.started":"2022-08-10T02:10:39.162131Z","shell.execute_reply":"2022-08-10T02:10:39.442274Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From the above graph, we can see that most of the skewness is removed.","metadata":{}},{"cell_type":"markdown","source":"# 4.4.2 Box Cox transforming the column - __year_resale_value","metadata":{}},{"cell_type":"code","source":"### Understanding the distribution of the column - __year_resale_value\n\nsns.distplot(modified_dataset['__year_resale_value'], label = 'Skewness: %.2f'%(modified_dataset['__year_resale_value'].skew()))\nplt.legend(loc = 'best')\nplt.title('Distribution of the column - __year_resale_value')","metadata":{"execution":{"iopub.status.busy":"2022-08-10T02:10:39.44492Z","iopub.execute_input":"2022-08-10T02:10:39.445452Z","iopub.status.idle":"2022-08-10T02:10:39.746893Z","shell.execute_reply.started":"2022-08-10T02:10:39.445416Z","shell.execute_reply":"2022-08-10T02:10:39.745845Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Understanding the distribution of the data Box_Cox(__year_resale_value)\n\nyear_data = [1 if value == 0 else value for value in modified_dataset['__year_resale_value']]\n\nmodified_year, _ = stats.boxcox(year_data)\nmodified_dataset['__year_resale_value'] = modified_year\n\nsns.distplot(modified_dataset['__year_resale_value'], label = 'Skewness: %.2f'%(modified_dataset['__year_resale_value'].skew()))\nplt.legend(loc = 'best')\nplt.title('Distribution of the column - __year_resale_value')","metadata":{"execution":{"iopub.status.busy":"2022-08-10T02:10:39.748645Z","iopub.execute_input":"2022-08-10T02:10:39.749455Z","iopub.status.idle":"2022-08-10T02:10:40.192393Z","shell.execute_reply.started":"2022-08-10T02:10:39.749405Z","shell.execute_reply":"2022-08-10T02:10:40.191335Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From the above graph, we can see that most of the skewness is removed.","metadata":{}},{"cell_type":"markdown","source":"# 4.4.3 Box Cox transforming the column - Engine_size","metadata":{}},{"cell_type":"code","source":"### Understanding the distribution of the column - Engine_size\n\nsns.distplot(modified_dataset['Engine_size'], label = 'Skewness: %.2f'%(modified_dataset['Engine_size'].skew()))\nplt.legend(loc = 'best')\nplt.title('Distribution of the column - Engine_size')","metadata":{"execution":{"iopub.status.busy":"2022-08-10T02:10:40.19399Z","iopub.execute_input":"2022-08-10T02:10:40.194662Z","iopub.status.idle":"2022-08-10T02:10:40.449331Z","shell.execute_reply.started":"2022-08-10T02:10:40.194623Z","shell.execute_reply":"2022-08-10T02:10:40.448043Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Understanding the distribution of the data Box_Cox(Engine_size)\n\nengine_data = [1 if value == 0 else value for value in modified_dataset['Engine_size']]\n\nmodified_engine, _ = stats.boxcox(engine_data)\nmodified_dataset['Engine_size'] = modified_engine\n\nsns.distplot(modified_dataset['Engine_size'], label = 'Skewness: %.2f'%(modified_dataset['Engine_size'].skew()))\nplt.legend(loc = 'best')\nplt.title('Distribution of the column - Engine_size')","metadata":{"execution":{"iopub.status.busy":"2022-08-10T02:10:40.450965Z","iopub.execute_input":"2022-08-10T02:10:40.451334Z","iopub.status.idle":"2022-08-10T02:10:40.718383Z","shell.execute_reply.started":"2022-08-10T02:10:40.4513Z","shell.execute_reply":"2022-08-10T02:10:40.717592Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From the above graph, we can see that most of the skewness is removed.","metadata":{}},{"cell_type":"markdown","source":"# 4.4.4 Box Cox transforming the column - Horsepower","metadata":{}},{"cell_type":"code","source":"### Understanding the distribution of the column - Horsepower\n\nsns.distplot(modified_dataset['Horsepower'], label = 'Skewness: %.2f'%(modified_dataset['Horsepower'].skew()))\nplt.legend(loc = 'best')\nplt.title('Distribution of the column - Horsepower')","metadata":{"execution":{"iopub.status.busy":"2022-08-10T02:10:40.719869Z","iopub.execute_input":"2022-08-10T02:10:40.720458Z","iopub.status.idle":"2022-08-10T02:10:40.982404Z","shell.execute_reply.started":"2022-08-10T02:10:40.720422Z","shell.execute_reply":"2022-08-10T02:10:40.981491Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Understanding the distribution of the data Box_Cox(Horsepower)\n\nhorsepower_data = [1 if value == 0 else value for value in modified_dataset['Horsepower']]\n\nmodified_horsepower, _ = stats.boxcox(horsepower_data)\nmodified_dataset['Horsepower'] = modified_horsepower\n\nsns.distplot(modified_dataset['Horsepower'], label = 'Skewness: %.2f'%(modified_dataset['Horsepower'].skew()))\nplt.legend(loc = 'best')\nplt.title('Distribution of the column - Horsepower')","metadata":{"execution":{"iopub.status.busy":"2022-08-10T02:10:40.983965Z","iopub.execute_input":"2022-08-10T02:10:40.984583Z","iopub.status.idle":"2022-08-10T02:10:41.25782Z","shell.execute_reply.started":"2022-08-10T02:10:40.984536Z","shell.execute_reply":"2022-08-10T02:10:41.256657Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From the above graph, we can see that most of the skewness is removed.","metadata":{}},{"cell_type":"markdown","source":"# 4.4.5 Box Cox transforming the column - Fuel_capacity","metadata":{}},{"cell_type":"code","source":"### Understanding the distribution of the column - Fuel_capacity\n\nsns.distplot(modified_dataset['Fuel_capacity'], label = 'Skewness: %.2f'%(modified_dataset['Fuel_capacity'].skew()))\nplt.legend(loc = 'best')\nplt.title('Distribution of the column - Fuel_capacity')","metadata":{"execution":{"iopub.status.busy":"2022-08-10T02:10:41.2594Z","iopub.execute_input":"2022-08-10T02:10:41.25998Z","iopub.status.idle":"2022-08-10T02:10:41.540569Z","shell.execute_reply.started":"2022-08-10T02:10:41.259934Z","shell.execute_reply":"2022-08-10T02:10:41.539406Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Understanding the distribution of the data Box_Cox(Fuel_capacity)\n\nfuel_data = [1 if value == 0 else value for value in modified_dataset['Fuel_capacity']]\n\nmodified_fuel, _ = stats.boxcox(fuel_data)\nmodified_dataset['Fuel_capacity'] = modified_fuel\n\nsns.distplot(modified_dataset['Fuel_capacity'], label = 'Skewness: %.2f'%(modified_dataset['Fuel_capacity'].skew()))\nplt.legend(loc = 'best')\nplt.title('Distribution of the column - Fuel_capacity')","metadata":{"execution":{"iopub.status.busy":"2022-08-10T02:10:41.541982Z","iopub.execute_input":"2022-08-10T02:10:41.542335Z","iopub.status.idle":"2022-08-10T02:10:41.816844Z","shell.execute_reply.started":"2022-08-10T02:10:41.542302Z","shell.execute_reply":"2022-08-10T02:10:41.815743Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From the above graph, we can see that most of the skewness is removed.","metadata":{}},{"cell_type":"markdown","source":"# 4.4.6 Box Cox transforming the column - Power_perf_factor","metadata":{}},{"cell_type":"code","source":"### Understanding the distribution of the column - Power_perf_factor\n\nsns.distplot(modified_dataset['Power_perf_factor'], label = 'Skewness: %.2f'%(modified_dataset['Power_perf_factor'].skew()))\nplt.legend(loc = 'best')\nplt.title('Distribution of the column - Power_perf_factor')","metadata":{"execution":{"iopub.status.busy":"2022-08-10T02:10:41.81824Z","iopub.execute_input":"2022-08-10T02:10:41.818825Z","iopub.status.idle":"2022-08-10T02:10:42.08658Z","shell.execute_reply.started":"2022-08-10T02:10:41.818785Z","shell.execute_reply":"2022-08-10T02:10:42.085653Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Understanding the distribution of the data Box_Cox(Power_perf_factor)\n\npower_data = [1 if value == 0 else value for value in modified_dataset['Power_perf_factor']]\n\nmodified_power, _ = stats.boxcox(power_data)\nmodified_dataset['Power_perf_factor'] = modified_power\n\nsns.distplot(modified_dataset['Power_perf_factor'], label = 'Skewness: %.2f'%(modified_dataset['Power_perf_factor'].skew()))\nplt.legend(loc = 'best')\nplt.title('Distribution of the column - Power_perf_factor')","metadata":{"execution":{"iopub.status.busy":"2022-08-10T02:10:42.087769Z","iopub.execute_input":"2022-08-10T02:10:42.088913Z","iopub.status.idle":"2022-08-10T02:10:42.360621Z","shell.execute_reply.started":"2022-08-10T02:10:42.088876Z","shell.execute_reply":"2022-08-10T02:10:42.359682Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From the above graph, we can see that most of the skewness is removed.","metadata":{}},{"cell_type":"markdown","source":"# 4.4.7 Normalizing the numerical columns","metadata":{}},{"cell_type":"code","source":"### A function to normalize numerical columns\n\ndef normalize_columns(dataframe, column):\n    data = dataframe[column]\n    mini = min(data)\n    maxi = max(data)\n    \n    new_data = []\n    for value in data:\n        new_data.append((value - mini)/(maxi - mini))\n    \n    dataframe[column] = new_data\n\nnumerical_columns = ['Sales_in_thousands', '__year_resale_value', 'Engine_size', 'Horsepower', 'Wheelbase', 'Width',\n                    'Length', 'Curb_weight', 'Fuel_capacity', 'Fuel_efficiency', 'Power_perf_factor', 'Age']\nfor each_column in numerical_columns:\n    normalize_columns(modified_dataset, each_column)","metadata":{"execution":{"iopub.status.busy":"2022-08-10T02:10:42.362043Z","iopub.execute_input":"2022-08-10T02:10:42.362634Z","iopub.status.idle":"2022-08-10T02:10:42.375069Z","shell.execute_reply.started":"2022-08-10T02:10:42.3626Z","shell.execute_reply":"2022-08-10T02:10:42.373632Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Looking at the sample records of the modified dataset\n\nmodified_dataset","metadata":{"execution":{"iopub.status.busy":"2022-08-10T02:10:42.376614Z","iopub.execute_input":"2022-08-10T02:10:42.377656Z","iopub.status.idle":"2022-08-10T02:10:42.412413Z","shell.execute_reply.started":"2022-08-10T02:10:42.377608Z","shell.execute_reply":"2022-08-10T02:10:42.410962Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4.5 Feature Encoding","metadata":{}},{"cell_type":"markdown","source":"Feature encoding is the process of turning categorical data in a dataset into numerical data. It is essential that we perform feature encoding because most machine learning models can only interpret numerical data and not data in text form.\n\nHere, we will use One Hot Encoding for the columns - Manufacturer, Vehicle_type.","metadata":{}},{"cell_type":"code","source":"### One Hot Encoding the columns - Manufacturer, Vehicle_type of the modified dataset\n\nencoded_dataset = pd.get_dummies(data = modified_dataset, columns = ['Manufacturer', 'Vehicle_type'])\nencoded_dataset","metadata":{"execution":{"iopub.status.busy":"2022-08-10T02:10:42.414534Z","iopub.execute_input":"2022-08-10T02:10:42.415129Z","iopub.status.idle":"2022-08-10T02:10:42.450277Z","shell.execute_reply.started":"2022-08-10T02:10:42.415081Z","shell.execute_reply":"2022-08-10T02:10:42.448882Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Create the column - Target using Price_in_thousands\n\ntarget_data = encoded_dataset['Price_in_thousands']\nencoded_dataset['Target'] = target_data\n\n### Dropping the column - Price_in_thousands\n\nencoded_dataset.drop(['Price_in_thousands'], axis = 1, inplace = True)\nencoded_dataset","metadata":{"execution":{"iopub.status.busy":"2022-08-10T02:10:42.451622Z","iopub.execute_input":"2022-08-10T02:10:42.452118Z","iopub.status.idle":"2022-08-10T02:10:42.484031Z","shell.execute_reply.started":"2022-08-10T02:10:42.452085Z","shell.execute_reply":"2022-08-10T02:10:42.4829Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4.6 Feature Selection","metadata":{}},{"cell_type":"markdown","source":"Feature selection is the process of reducing the number of input variables when developing a predictive model. It is desirable to reduce the number of input variables to both reduce the computational cost of modeling and, in some cases, to improve the performance of the model.","metadata":{}},{"cell_type":"markdown","source":"# 4.6.1 Plotting the correlation matrix for the numerical columns","metadata":{}},{"cell_type":"code","source":"### Creating a filter_dataset\n\nfilter_dataset = encoded_dataset[['Sales_in_thousands', '__year_resale_value', 'Engine_size', 'Horsepower', 'Wheelbase', \n                                  'Width', 'Length', 'Curb_weight', 'Fuel_capacity', 'Fuel_efficiency', 'Power_perf_factor',\n                                  'Age']]\nfilter_dataset","metadata":{"execution":{"iopub.status.busy":"2022-08-10T02:10:42.485423Z","iopub.execute_input":"2022-08-10T02:10:42.486189Z","iopub.status.idle":"2022-08-10T02:10:42.511584Z","shell.execute_reply.started":"2022-08-10T02:10:42.486152Z","shell.execute_reply":"2022-08-10T02:10:42.510205Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Plotting the correlation between various columns of the filter_dataset\n\nplt.figure(figsize = (10, 10))\nheatmap = sns.heatmap(filter_dataset.corr(), vmin = -1, vmax = 1, annot = True)\nheatmap.set_title('Correlation Heatmap', fontdict = {'fontsize' : 12}, pad = 12)","metadata":{"execution":{"iopub.status.busy":"2022-08-10T02:10:42.513157Z","iopub.execute_input":"2022-08-10T02:10:42.513623Z","iopub.status.idle":"2022-08-10T02:10:43.442317Z","shell.execute_reply.started":"2022-08-10T02:10:42.513589Z","shell.execute_reply":"2022-08-10T02:10:43.441019Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From the above correlation matrix, we can see that there are a few strong correlations between the data. We will use VIF to remove the multi collinearity.","metadata":{}},{"cell_type":"markdown","source":"# 4.6.2 Removing the columns that cause multicollinearity using VIF","metadata":{}},{"cell_type":"code","source":"### Detecting the columns that cause multicollinearity using VIF\n\ncolumn_names = list(filter_dataset.columns)\n\nfor name in column_names:\n    if len(column_names) >= 2:\n        Y = filter_dataset.loc[:, filter_dataset.columns == name]\n        X = filter_dataset.loc[:, filter_dataset.columns != name]\n        X = sm.add_constant(X)\n        linear_model = sm.OLS(Y, X)\n        results = linear_model.fit()\n        r_squared = results.rsquared\n        vif_value = round(1/(1 - r_squared), 2)\n        print(\"Column: {} and VIF: {}\".format(name, vif_value))\n        \n        if vif_value > 10:\n            filter_dataset = filter_dataset.drop([name], axis = 1)\n            column_names.remove(name)","metadata":{"execution":{"iopub.status.busy":"2022-08-10T02:10:43.444048Z","iopub.execute_input":"2022-08-10T02:10:43.444797Z","iopub.status.idle":"2022-08-10T02:10:43.519268Z","shell.execute_reply.started":"2022-08-10T02:10:43.444752Z","shell.execute_reply":"2022-08-10T02:10:43.518005Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From the above data, we can see that the columns - Engine_size, Horsepower, Curb_weight, Fuel_capacity, Power_perf_factor cause multicollinearity.","metadata":{}},{"cell_type":"markdown","source":"# 5. Modelling","metadata":{}},{"cell_type":"markdown","source":"Scikit-learn is one of the most popular libraries for machine learning in Python and that is what we will use in the modelling part of this project.\n\nSince Car Price Prediction is a regression problem, we will need to use regression models, also known as regressors, to train on our model to make predictions. I highly recommend checking out the scikit-learn documentation for more information on the different machine learning models available in their library. I have chosen the following regression models for the job:\n\n1. Multi Linear Regression\n2. Lasso Regression\n3. Ridge Regression\n4. Support Vector Regression\n5. Decision Tree regression\n6. Random Forest Regression\n7. Stacking Regression\n8. XGBoost Regression\n\nIn this section of the notebook, I will fit the models to the training set as outlined above and evaluate their Root Mean Squared Error (RMSE), R-squared at making predictions. Then, we will select the best model based on those values.","metadata":{}},{"cell_type":"markdown","source":"# 5.1 Splitting the data to Training and Test sets","metadata":{}},{"cell_type":"markdown","source":"Here, we will split the training data into X_train, X_test, Y_train, and Y_test so that they can be fed to the machine learning models that are used in the next section. Then the model with the best performance will be used to predict the result on the given test dataset.","metadata":{}},{"cell_type":"code","source":"### Splitting the dataset to the matrices X and Y\n\nX = encoded_dataset.iloc[:, : -1].values\nY = encoded_dataset.iloc[:, -1].values","metadata":{"execution":{"iopub.status.busy":"2022-08-10T02:10:43.521052Z","iopub.execute_input":"2022-08-10T02:10:43.521524Z","iopub.status.idle":"2022-08-10T02:10:43.528364Z","shell.execute_reply.started":"2022-08-10T02:10:43.521468Z","shell.execute_reply":"2022-08-10T02:10:43.527157Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Looking at the new training data - X\n\nX","metadata":{"execution":{"iopub.status.busy":"2022-08-10T02:10:43.529953Z","iopub.execute_input":"2022-08-10T02:10:43.530493Z","iopub.status.idle":"2022-08-10T02:10:43.541882Z","shell.execute_reply.started":"2022-08-10T02:10:43.530463Z","shell.execute_reply":"2022-08-10T02:10:43.540815Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Looking at the new test data - Y\n\nY","metadata":{"execution":{"iopub.status.busy":"2022-08-10T02:10:43.543664Z","iopub.execute_input":"2022-08-10T02:10:43.544864Z","iopub.status.idle":"2022-08-10T02:10:43.555927Z","shell.execute_reply.started":"2022-08-10T02:10:43.544817Z","shell.execute_reply":"2022-08-10T02:10:43.55462Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Dividing the dataset into train and test in the ratio of 80 : 20\n\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, random_state = 27, shuffle = True)","metadata":{"execution":{"iopub.status.busy":"2022-08-10T02:10:43.559083Z","iopub.execute_input":"2022-08-10T02:10:43.560062Z","iopub.status.idle":"2022-08-10T02:10:43.566933Z","shell.execute_reply.started":"2022-08-10T02:10:43.559974Z","shell.execute_reply":"2022-08-10T02:10:43.565637Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now, we apply regressors using the above data.","metadata":{}},{"cell_type":"markdown","source":"# 5.2 Fit the model","metadata":{}},{"cell_type":"markdown","source":"In this section, we use various machine learning models to predict the results for our test data (X_test). We will store the model and its corresponding Root Mean Squared Error and Adjusted R-squared so that we can tabulate them later for choosing the best model.","metadata":{}},{"cell_type":"code","source":"### Dictionary to store model and its rmse\n\nmodel_rmse = OrderedDict()","metadata":{"execution":{"iopub.status.busy":"2022-08-10T02:10:43.570131Z","iopub.execute_input":"2022-08-10T02:10:43.570889Z","iopub.status.idle":"2022-08-10T02:10:43.578395Z","shell.execute_reply.started":"2022-08-10T02:10:43.570846Z","shell.execute_reply":"2022-08-10T02:10:43.577284Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Dictionary to store model and its r-squared\n\nmodel_r2 = OrderedDict()","metadata":{"execution":{"iopub.status.busy":"2022-08-10T02:10:43.580114Z","iopub.execute_input":"2022-08-10T02:10:43.580764Z","iopub.status.idle":"2022-08-10T02:10:43.58997Z","shell.execute_reply.started":"2022-08-10T02:10:43.580727Z","shell.execute_reply":"2022-08-10T02:10:43.588933Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 5.2.1 Applying Multi Linear Regression","metadata":{}},{"cell_type":"code","source":"### Training the Multi Linear Regression model on the Training set\n\nlinear_regressor = LinearRegression()\nlinear_regressor.fit(X_train, Y_train)","metadata":{"execution":{"iopub.status.busy":"2022-08-10T02:10:43.59144Z","iopub.execute_input":"2022-08-10T02:10:43.591815Z","iopub.status.idle":"2022-08-10T02:10:43.620786Z","shell.execute_reply.started":"2022-08-10T02:10:43.591781Z","shell.execute_reply":"2022-08-10T02:10:43.619651Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Predicting the Test set results\n\nY_pred = linear_regressor.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2022-08-10T02:10:43.622975Z","iopub.execute_input":"2022-08-10T02:10:43.623823Z","iopub.status.idle":"2022-08-10T02:10:43.629752Z","shell.execute_reply.started":"2022-08-10T02:10:43.623775Z","shell.execute_reply":"2022-08-10T02:10:43.628635Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Calculating RMSE and Adjusted R-squared for the model\n\nmse = round(mean_squared_error(Y_test, Y_pred), 3)\nrmse = round(sqrt(mse), 3)\n\nr2_value = round(r2_score(Y_test, Y_pred), 3)\n\nmodel_rmse['Multi Linear Regression'] = rmse\nmodel_r2['Multi Linear Regression'] = r2_value\n\nprint('Root Mean Squared Error of the model is : {}'.format(rmse))\nprint('R-squared value of the model is : {}'.format(r2_value))","metadata":{"execution":{"iopub.status.busy":"2022-08-10T02:10:43.631978Z","iopub.execute_input":"2022-08-10T02:10:43.63291Z","iopub.status.idle":"2022-08-10T02:10:43.645261Z","shell.execute_reply.started":"2022-08-10T02:10:43.632862Z","shell.execute_reply":"2022-08-10T02:10:43.643974Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 5.2.2 Applying Lasso Regression","metadata":{}},{"cell_type":"code","source":"### Training the Lasso Regression model on the Training set\n\nlasso = Lasso()\nparameters = {'alpha': [1e-15, 1e-10, 1e-8, 1e-3, 1e-2, 1, 5, 10, 20, 30, 35, 40, 45, 50, 55, 100]}\nlasso_regressor = GridSearchCV(lasso, parameters, scoring = 'neg_mean_squared_error', cv = 5)\nlasso_regressor.fit(X_train, Y_train)","metadata":{"execution":{"iopub.status.busy":"2022-08-10T02:10:43.646659Z","iopub.execute_input":"2022-08-10T02:10:43.64702Z","iopub.status.idle":"2022-08-10T02:10:43.846614Z","shell.execute_reply.started":"2022-08-10T02:10:43.646987Z","shell.execute_reply":"2022-08-10T02:10:43.845764Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Finding out negative mean squared error in Lasso Regression\n\nprint(lasso_regressor.best_params_)\nprint(lasso_regressor.best_score_)","metadata":{"execution":{"iopub.status.busy":"2022-08-10T02:10:43.847728Z","iopub.execute_input":"2022-08-10T02:10:43.848646Z","iopub.status.idle":"2022-08-10T02:10:43.854165Z","shell.execute_reply.started":"2022-08-10T02:10:43.848608Z","shell.execute_reply":"2022-08-10T02:10:43.852767Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Predicting the Test set results\n\nY_pred = lasso_regressor.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2022-08-10T02:10:43.855869Z","iopub.execute_input":"2022-08-10T02:10:43.856987Z","iopub.status.idle":"2022-08-10T02:10:43.864647Z","shell.execute_reply.started":"2022-08-10T02:10:43.856939Z","shell.execute_reply":"2022-08-10T02:10:43.863754Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Calculating RMSE and Adjusted R-squared for the model\n\nmse = round(mean_squared_error(Y_test, Y_pred), 3)\nrmse = round(sqrt(mse), 3)\n\nr2_value = round(r2_score(Y_test, Y_pred), 3)\n\nmodel_rmse['Lasso Regression'] = rmse\nmodel_r2['Lasso Regression'] = r2_value\n\nprint('Root Mean Squared Error of the model is : {}'.format(rmse))\nprint('R-squared value of the model is : {}'.format(r2_value))","metadata":{"execution":{"iopub.status.busy":"2022-08-10T02:10:43.878127Z","iopub.execute_input":"2022-08-10T02:10:43.87892Z","iopub.status.idle":"2022-08-10T02:10:43.887947Z","shell.execute_reply.started":"2022-08-10T02:10:43.878868Z","shell.execute_reply":"2022-08-10T02:10:43.886793Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 5.2.3 Applying Ridge Regression","metadata":{}},{"cell_type":"code","source":"### Training the Ridge Regression model on the Training set\n\nridge = Ridge()\nparameters = {'alpha': [1e-15, 1e-10, 1e-8, 1e-3, 1e-2, 1, 5, 10, 20, 30, 35, 40, 45, 50, 55, 100]}\nridge_regressor = GridSearchCV(ridge, parameters, scoring = 'neg_mean_squared_error', cv = 5)\nridge_regressor.fit(X_train, Y_train)","metadata":{"execution":{"iopub.status.busy":"2022-08-10T02:10:43.889615Z","iopub.execute_input":"2022-08-10T02:10:43.890224Z","iopub.status.idle":"2022-08-10T02:10:44.028853Z","shell.execute_reply.started":"2022-08-10T02:10:43.890187Z","shell.execute_reply":"2022-08-10T02:10:44.027544Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Finding out negative mean squared error in Lasso Regression\n\nprint(ridge_regressor.best_params_)\nprint(ridge_regressor.best_score_)","metadata":{"execution":{"iopub.status.busy":"2022-08-10T02:10:44.030264Z","iopub.execute_input":"2022-08-10T02:10:44.030743Z","iopub.status.idle":"2022-08-10T02:10:44.038098Z","shell.execute_reply.started":"2022-08-10T02:10:44.030701Z","shell.execute_reply":"2022-08-10T02:10:44.036834Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Predicting the Test set results\n\nY_pred = ridge_regressor.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2022-08-10T02:10:44.039752Z","iopub.execute_input":"2022-08-10T02:10:44.040095Z","iopub.status.idle":"2022-08-10T02:10:44.053415Z","shell.execute_reply.started":"2022-08-10T02:10:44.040062Z","shell.execute_reply":"2022-08-10T02:10:44.05239Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Calculating RMSE and Adjusted R-squared for the model\n\nmse = round(mean_squared_error(Y_test, Y_pred), 3)\nrmse = round(sqrt(mse), 3)\n\nr2_value = round(r2_score(Y_test, Y_pred), 3)\n\nmodel_rmse['Ridge Regression'] = rmse\nmodel_r2['Ridge Regression'] = r2_value\n\nprint('Root Mean Squared Error of the model is : {}'.format(rmse))\nprint('R-squared value of the model is : {}'.format(r2_value))","metadata":{"execution":{"iopub.status.busy":"2022-08-10T02:10:44.054482Z","iopub.execute_input":"2022-08-10T02:10:44.054865Z","iopub.status.idle":"2022-08-10T02:10:44.06947Z","shell.execute_reply.started":"2022-08-10T02:10:44.054832Z","shell.execute_reply":"2022-08-10T02:10:44.068606Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 5.2.4 Applying Support Vector Regression","metadata":{}},{"cell_type":"code","source":"### Training the Support Vector Regression model on the Training set\n\nsupport_vector_regressor = SVR(kernel = 'rbf')\nsupport_vector_regressor.fit(X_train, Y_train)","metadata":{"execution":{"iopub.status.busy":"2022-08-10T02:10:44.070637Z","iopub.execute_input":"2022-08-10T02:10:44.071076Z","iopub.status.idle":"2022-08-10T02:10:44.090298Z","shell.execute_reply.started":"2022-08-10T02:10:44.071032Z","shell.execute_reply":"2022-08-10T02:10:44.089074Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Predicting the Test set results\n\nY_pred = support_vector_regressor.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2022-08-10T02:10:44.092162Z","iopub.execute_input":"2022-08-10T02:10:44.092667Z","iopub.status.idle":"2022-08-10T02:10:44.100916Z","shell.execute_reply.started":"2022-08-10T02:10:44.092621Z","shell.execute_reply":"2022-08-10T02:10:44.099835Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Calculating RMSE and Adjusted R-squared for the model\n\nmse = round(mean_squared_error(Y_test, Y_pred), 3)\nrmse = round(sqrt(mse), 3)\n\nr2_value = round(r2_score(Y_test, Y_pred), 3)\n\nmodel_rmse['Support Vector Regression'] = rmse\nmodel_r2['Support Vector Regression'] = r2_value\n\nprint('Root Mean Squared Error of the model is : {}'.format(rmse))\nprint('R-squared value of the model is : {}'.format(r2_value))","metadata":{"execution":{"iopub.status.busy":"2022-08-10T02:10:44.103187Z","iopub.execute_input":"2022-08-10T02:10:44.103762Z","iopub.status.idle":"2022-08-10T02:10:44.113971Z","shell.execute_reply.started":"2022-08-10T02:10:44.1037Z","shell.execute_reply":"2022-08-10T02:10:44.112649Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 5.2.5 Applying Decision Tree Regression","metadata":{}},{"cell_type":"code","source":"### Training the Decision Tree Regression model on the Training set\n\ndecision_tree_regressor = DecisionTreeRegressor()\ndecision_tree_regressor.fit(X_train, Y_train)","metadata":{"execution":{"iopub.status.busy":"2022-08-10T02:10:44.115209Z","iopub.execute_input":"2022-08-10T02:10:44.115678Z","iopub.status.idle":"2022-08-10T02:10:44.132822Z","shell.execute_reply.started":"2022-08-10T02:10:44.115623Z","shell.execute_reply":"2022-08-10T02:10:44.131782Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Predicting the Test set results\n\nY_pred = decision_tree_regressor.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2022-08-10T02:10:44.134251Z","iopub.execute_input":"2022-08-10T02:10:44.135451Z","iopub.status.idle":"2022-08-10T02:10:44.140622Z","shell.execute_reply.started":"2022-08-10T02:10:44.135405Z","shell.execute_reply":"2022-08-10T02:10:44.139304Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Calculating RMSE and Adjusted R-squared for the model\n\nmse = round(mean_squared_error(Y_test, Y_pred), 3)\nrmse = round(sqrt(mse), 3)\n\nr2_value = round(r2_score(Y_test, Y_pred), 3)\n\nmodel_rmse['Decision Tree Regression'] = rmse\nmodel_r2['Decision Tree Regression'] = r2_value\n\nprint('Root Mean Squared Error of the model is : {}'.format(rmse))\nprint('R-squared value of the model is : {}'.format(r2_value))","metadata":{"execution":{"iopub.status.busy":"2022-08-10T02:10:44.141688Z","iopub.execute_input":"2022-08-10T02:10:44.142031Z","iopub.status.idle":"2022-08-10T02:10:44.154708Z","shell.execute_reply.started":"2022-08-10T02:10:44.142Z","shell.execute_reply":"2022-08-10T02:10:44.153648Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 5.2.6 Applying Random Forest Regression (10 trees)","metadata":{}},{"cell_type":"code","source":"### Training the Random Forest Regression model on the Training set\n\nrandom_forest_regressor = RandomForestRegressor(n_estimators = 10, random_state = 27)\nrandom_forest_regressor.fit(X_train, Y_train)","metadata":{"execution":{"iopub.status.busy":"2022-08-10T02:10:44.156127Z","iopub.execute_input":"2022-08-10T02:10:44.156468Z","iopub.status.idle":"2022-08-10T02:10:44.187682Z","shell.execute_reply.started":"2022-08-10T02:10:44.156438Z","shell.execute_reply":"2022-08-10T02:10:44.186479Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Predicting the Test set results\n\nY_pred = random_forest_regressor.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2022-08-10T02:10:44.189384Z","iopub.execute_input":"2022-08-10T02:10:44.189841Z","iopub.status.idle":"2022-08-10T02:10:44.19755Z","shell.execute_reply.started":"2022-08-10T02:10:44.189795Z","shell.execute_reply":"2022-08-10T02:10:44.196598Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Calculating RMSE and Adjusted R-squared for the model\n\nmse = round(mean_squared_error(Y_test, Y_pred), 3)\nrmse = round(sqrt(mse), 3)\n\nr2_value = round(r2_score(Y_test, Y_pred), 3)\n\nmodel_rmse['Random Forest Regression (10 trees)'] = rmse\nmodel_r2['Random Forest Regression (10 trees)'] = r2_value\n\nprint('Root Mean Squared Error of the model is : {}'.format(rmse))\nprint('R-squared value of the model is : {}'.format(r2_value))","metadata":{"execution":{"iopub.status.busy":"2022-08-10T02:10:44.198691Z","iopub.execute_input":"2022-08-10T02:10:44.199092Z","iopub.status.idle":"2022-08-10T02:10:44.213004Z","shell.execute_reply.started":"2022-08-10T02:10:44.199053Z","shell.execute_reply":"2022-08-10T02:10:44.211847Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 5.2.7 Applying Random Forest Regression (25 trees)","metadata":{}},{"cell_type":"code","source":"### Training the Random Forest Regression model on the Training set\n\nrandom_forest_regressor = RandomForestRegressor(n_estimators = 25, random_state = 27)\nrandom_forest_regressor.fit(X_train, Y_train)","metadata":{"execution":{"iopub.status.busy":"2022-08-10T02:10:44.214716Z","iopub.execute_input":"2022-08-10T02:10:44.215365Z","iopub.status.idle":"2022-08-10T02:10:44.270404Z","shell.execute_reply.started":"2022-08-10T02:10:44.215318Z","shell.execute_reply":"2022-08-10T02:10:44.269156Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Predicting the Test set results\n\nY_pred = random_forest_regressor.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2022-08-10T02:10:44.271636Z","iopub.execute_input":"2022-08-10T02:10:44.271943Z","iopub.status.idle":"2022-08-10T02:10:44.281198Z","shell.execute_reply.started":"2022-08-10T02:10:44.271914Z","shell.execute_reply":"2022-08-10T02:10:44.280215Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Calculating RMSE and Adjusted R-squared for the model\n\nmse = round(mean_squared_error(Y_test, Y_pred), 3)\nrmse = round(sqrt(mse), 3)\n\nr2_value = round(r2_score(Y_test, Y_pred), 3)\n\nmodel_rmse['Random Forest Regression (25 trees)'] = rmse\nmodel_r2['Random Forest Regression (25 trees)'] = r2_value\n\nprint('Root Mean Squared Error of the model is : {}'.format(rmse))\nprint('R-squared value of the model is : {}'.format(r2_value))","metadata":{"execution":{"iopub.status.busy":"2022-08-10T02:10:44.282845Z","iopub.execute_input":"2022-08-10T02:10:44.283906Z","iopub.status.idle":"2022-08-10T02:10:44.292672Z","shell.execute_reply.started":"2022-08-10T02:10:44.283848Z","shell.execute_reply":"2022-08-10T02:10:44.291598Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 5.2.8 Applying Random Forest Regression (50 trees)","metadata":{}},{"cell_type":"code","source":"### Training the Random Forest Regression model on the Training set\n\nrandom_forest_regressor = RandomForestRegressor(n_estimators = 50, random_state = 27)\nrandom_forest_regressor.fit(X_train, Y_train)","metadata":{"execution":{"iopub.status.busy":"2022-08-10T02:10:44.29403Z","iopub.execute_input":"2022-08-10T02:10:44.29514Z","iopub.status.idle":"2022-08-10T02:10:44.392937Z","shell.execute_reply.started":"2022-08-10T02:10:44.2951Z","shell.execute_reply":"2022-08-10T02:10:44.39215Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Predicting the Test set results\n\nY_pred = random_forest_regressor.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2022-08-10T02:10:44.393962Z","iopub.execute_input":"2022-08-10T02:10:44.394462Z","iopub.status.idle":"2022-08-10T02:10:44.404406Z","shell.execute_reply.started":"2022-08-10T02:10:44.39443Z","shell.execute_reply":"2022-08-10T02:10:44.40333Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Calculating RMSE and Adjusted R-squared for the model\n\nmse = round(mean_squared_error(Y_test, Y_pred), 3)\nrmse = round(sqrt(mse), 3)\n\nr2_value = round(r2_score(Y_test, Y_pred), 3)\n\nmodel_rmse['Random Forest Regression (50 trees)'] = rmse\nmodel_r2['Random Forest Regression (50 trees)'] = r2_value\n\nprint('Root Mean Squared Error of the model is : {}'.format(rmse))\nprint('R-squared value of the model is : {}'.format(r2_value))","metadata":{"execution":{"iopub.status.busy":"2022-08-10T02:10:44.406196Z","iopub.execute_input":"2022-08-10T02:10:44.407791Z","iopub.status.idle":"2022-08-10T02:10:44.417682Z","shell.execute_reply.started":"2022-08-10T02:10:44.407755Z","shell.execute_reply":"2022-08-10T02:10:44.41646Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 5.2.9 Applying Random Forest Regression (100 trees)","metadata":{}},{"cell_type":"code","source":"### Training the Random Forest Regression model on the Training set\n\nrandom_forest_regressor = RandomForestRegressor(n_estimators = 100, random_state = 27)\nrandom_forest_regressor.fit(X_train, Y_train)","metadata":{"execution":{"iopub.status.busy":"2022-08-10T02:10:44.420808Z","iopub.execute_input":"2022-08-10T02:10:44.421375Z","iopub.status.idle":"2022-08-10T02:10:44.595808Z","shell.execute_reply.started":"2022-08-10T02:10:44.421329Z","shell.execute_reply":"2022-08-10T02:10:44.594616Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Predicting the Test set results\n\nY_pred = random_forest_regressor.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2022-08-10T02:10:44.597271Z","iopub.execute_input":"2022-08-10T02:10:44.597659Z","iopub.status.idle":"2022-08-10T02:10:44.618387Z","shell.execute_reply.started":"2022-08-10T02:10:44.597625Z","shell.execute_reply":"2022-08-10T02:10:44.61727Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Calculating RMSE and Adjusted R-squared for the model\n\nmse = round(mean_squared_error(Y_test, Y_pred), 3)\nrmse = round(sqrt(mse), 3)\n\nr2_value = round(r2_score(Y_test, Y_pred), 3)\n\nmodel_rmse['Random Forest Regression (100 trees)'] = rmse\nmodel_r2['Random Forest Regression (100 trees)'] = r2_value\n\nprint('Root Mean Squared Error of the model is : {}'.format(rmse))\nprint('R-squared value of the model is : {}'.format(r2_value))","metadata":{"execution":{"iopub.status.busy":"2022-08-10T02:10:44.620186Z","iopub.execute_input":"2022-08-10T02:10:44.620541Z","iopub.status.idle":"2022-08-10T02:10:44.629752Z","shell.execute_reply.started":"2022-08-10T02:10:44.620508Z","shell.execute_reply":"2022-08-10T02:10:44.628448Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 5.2.10 Applying Random Forest Regression (1000 trees)","metadata":{}},{"cell_type":"code","source":"### Training the Random Forest Regression model on the Training set\n\nrandom_forest_regressor = RandomForestRegressor(n_estimators = 1000, random_state = 27)\nrandom_forest_regressor.fit(X_train, Y_train)","metadata":{"execution":{"iopub.status.busy":"2022-08-10T02:10:44.632673Z","iopub.execute_input":"2022-08-10T02:10:44.633058Z","iopub.status.idle":"2022-08-10T02:10:46.256703Z","shell.execute_reply.started":"2022-08-10T02:10:44.633025Z","shell.execute_reply":"2022-08-10T02:10:46.25551Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Predicting the Test set results\n\nY_pred = random_forest_regressor.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2022-08-10T02:10:46.258105Z","iopub.execute_input":"2022-08-10T02:10:46.258442Z","iopub.status.idle":"2022-08-10T02:10:46.350757Z","shell.execute_reply.started":"2022-08-10T02:10:46.25841Z","shell.execute_reply":"2022-08-10T02:10:46.349715Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Calculating RMSE and Adjusted R-squared for the model\n\nmse = round(mean_squared_error(Y_test, Y_pred), 3)\nrmse = round(sqrt(mse), 3)\n\nr2_value = round(r2_score(Y_test, Y_pred), 3)\n\nmodel_rmse['Random Forest Regression (1000 trees)'] = rmse\nmodel_r2['Random Forest Regression (1000 trees)'] = r2_value\n\nprint('Root Mean Squared Error of the model is : {}'.format(rmse))\nprint('R-squared value of the model is : {}'.format(r2_value))","metadata":{"execution":{"iopub.status.busy":"2022-08-10T02:10:46.352064Z","iopub.execute_input":"2022-08-10T02:10:46.352477Z","iopub.status.idle":"2022-08-10T02:10:46.360202Z","shell.execute_reply.started":"2022-08-10T02:10:46.352445Z","shell.execute_reply":"2022-08-10T02:10:46.359174Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 5.2.11 Applying Stacking Regression","metadata":{}},{"cell_type":"code","source":"### Preparing the Stacking Regressor\n\n### Define the base models\n\nbase_models = list()\n\nbase_models.append(('decision_tree', decision_tree_regressor))\nbase_models.append(('support_vector', support_vector_regressor))\n\n### Define the meta models\n\nmeta_model = random_forest_regressor","metadata":{"execution":{"iopub.status.busy":"2022-08-10T02:10:46.361404Z","iopub.execute_input":"2022-08-10T02:10:46.362443Z","iopub.status.idle":"2022-08-10T02:10:46.372545Z","shell.execute_reply.started":"2022-08-10T02:10:46.362405Z","shell.execute_reply":"2022-08-10T02:10:46.371425Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Training the Stacking Regression model on the Training set\n\nstacking_regressor = StackingRegressor(estimators = base_models, final_estimator = meta_model)\nstacking_regressor.fit(X_train, Y_train)","metadata":{"execution":{"iopub.status.busy":"2022-08-10T02:10:46.374065Z","iopub.execute_input":"2022-08-10T02:10:46.374422Z","iopub.status.idle":"2022-08-10T02:10:47.684168Z","shell.execute_reply.started":"2022-08-10T02:10:46.374389Z","shell.execute_reply":"2022-08-10T02:10:47.68276Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Predicting the Test set results\n\nY_pred = stacking_regressor.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2022-08-10T02:10:47.685615Z","iopub.execute_input":"2022-08-10T02:10:47.68598Z","iopub.status.idle":"2022-08-10T02:10:47.777128Z","shell.execute_reply.started":"2022-08-10T02:10:47.685949Z","shell.execute_reply":"2022-08-10T02:10:47.775918Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Calculating RMSE and Adjusted R-squared for the model\n\nmse = round(mean_squared_error(Y_test, Y_pred), 3)\nrmse = round(sqrt(mse), 3)\n\nr2_value = round(r2_score(Y_test, Y_pred), 3)\n\nmodel_rmse['Stacking Regression'] = rmse\nmodel_r2['Stacking Regression'] = r2_value\n\nprint('Root Mean Squared Error of the model is : {}'.format(rmse))\nprint('R-squared value of the model is : {}'.format(r2_value))","metadata":{"execution":{"iopub.status.busy":"2022-08-10T02:10:47.778711Z","iopub.execute_input":"2022-08-10T02:10:47.779081Z","iopub.status.idle":"2022-08-10T02:10:47.788691Z","shell.execute_reply.started":"2022-08-10T02:10:47.779048Z","shell.execute_reply":"2022-08-10T02:10:47.787375Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 5.2.12 Applying XGBoost Regression","metadata":{}},{"cell_type":"code","source":"### Training the XGBoost Regression model on the Training set\n\nxgboost_regressor = xg.XGBRegressor(objective ='reg:linear', n_estimators = 100, seed = 27)\nxgboost_regressor.fit(X_train, Y_train)","metadata":{"execution":{"iopub.status.busy":"2022-08-10T02:10:47.790277Z","iopub.execute_input":"2022-08-10T02:10:47.791253Z","iopub.status.idle":"2022-08-10T02:10:48.232603Z","shell.execute_reply.started":"2022-08-10T02:10:47.791215Z","shell.execute_reply":"2022-08-10T02:10:48.231702Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Predicting the Test set results\n\nY_pred = xgboost_regressor.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2022-08-10T02:10:48.236366Z","iopub.execute_input":"2022-08-10T02:10:48.236752Z","iopub.status.idle":"2022-08-10T02:10:48.246705Z","shell.execute_reply.started":"2022-08-10T02:10:48.236719Z","shell.execute_reply":"2022-08-10T02:10:48.245627Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Calculating RMSE and Adjusted R-squared for the model\n\nmse = round(mean_squared_error(Y_test, Y_pred), 3)\nrmse = round(sqrt(mse), 3)\n\nr2_value = round(r2_score(Y_test, Y_pred), 3)\n\nmodel_rmse['XGBoost Regression'] = rmse\nmodel_r2['XGBoost Regression'] = r2_value\n\nprint('Root Mean Squared Error of the model is : {}'.format(rmse))\nprint('R-squared value of the model is : {}'.format(r2_value))","metadata":{"execution":{"iopub.status.busy":"2022-08-10T02:10:48.248247Z","iopub.execute_input":"2022-08-10T02:10:48.249073Z","iopub.status.idle":"2022-08-10T02:10:48.258213Z","shell.execute_reply.started":"2022-08-10T02:10:48.249034Z","shell.execute_reply":"2022-08-10T02:10:48.257302Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 5.3 Model evalution","metadata":{}},{"cell_type":"markdown","source":"Model evaluation is the process of using different evaluation metrics to understand a machine learning model's performance, as well as its strengths and weaknesses.","metadata":{}},{"cell_type":"markdown","source":"# 5.3.1 RMSE, R-squared of the models","metadata":{}},{"cell_type":"markdown","source":"Now we will tabulate all the models along with their RMSE, R-Squared. This data is stored in the model_rmse, model_r2 dictionary. We will use the tabulate package for tabulating the results.","metadata":{}},{"cell_type":"code","source":"### Looking at the model rmse dictionary\n\nmodel_rmse","metadata":{"execution":{"iopub.status.busy":"2022-08-10T02:10:48.259914Z","iopub.execute_input":"2022-08-10T02:10:48.261723Z","iopub.status.idle":"2022-08-10T02:10:48.270867Z","shell.execute_reply.started":"2022-08-10T02:10:48.261674Z","shell.execute_reply":"2022-08-10T02:10:48.269642Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Looking at the model r-squared dictionary\n\nmodel_r2","metadata":{"execution":{"iopub.status.busy":"2022-08-10T02:10:48.272458Z","iopub.execute_input":"2022-08-10T02:10:48.27342Z","iopub.status.idle":"2022-08-10T02:10:48.284234Z","shell.execute_reply.started":"2022-08-10T02:10:48.273373Z","shell.execute_reply":"2022-08-10T02:10:48.282777Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Tabulating the results\n\ntable = []\ntable.append(['S.No.', 'Classification Model', 'Root Mean Squared Error', 'R-squared'])\ncount = 1\n\nfor model in model_rmse:\n    row = [count, model, model_rmse[model], model_r2[model]]\n    table.append(row)\n    count += 1\n    \nprint(tabulate(table, headers = 'firstrow', tablefmt = 'fancy_grid'))","metadata":{"execution":{"iopub.status.busy":"2022-08-10T02:10:48.286894Z","iopub.execute_input":"2022-08-10T02:10:48.287851Z","iopub.status.idle":"2022-08-10T02:10:48.297912Z","shell.execute_reply.started":"2022-08-10T02:10:48.28781Z","shell.execute_reply":"2022-08-10T02:10:48.296837Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From the above table, we can see that the model Linear Regression has the least Root Mean Squared Error of 4.245 and the highest R-squared value of 0.926.","metadata":{}},{"cell_type":"markdown","source":"# 6. Conclusion","metadata":{}},{"cell_type":"markdown","source":"Hence, for this problem, we will use Linear regressor to predict the Sales Price of the Car.","metadata":{}}]}